{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### definitions\n",
    "**underflow:** numbers near zero are rounded to zero\n",
    "\n",
    "**overflow:** large-magnitude numbers are approximated as $\\infty$ or $-\\infty$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**softmax:**\n",
    "\n",
    "$$\\text{softmax}(\\boldsymbol{x})_{i} = \\frac{\\text{exp}(x_{i})}{\\sum_{j=1}^{n} \\text{exp}(x_{j})}$$\n",
    "\n",
    "Softmax must be stabilized against underflow and overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    print(\"\\t(denominator =\", np.sum(np.exp(x)), \")\")\n",
    "    return np.exp(x)/np.sum(np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = [4.0, 6.0, 8.0] \n",
      "\n",
      "\t(denominator = 3438.98493057 )\n",
      "softmax(x) = [ 0.01587624  0.11731043  0.86681333] \n",
      "\n",
      "\t(denominator = 3438.98493057 )\n",
      "sum(softmax(x))= 1.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# non-problematic example\n",
    "x = [4.0, 6.0, 8.0]\n",
    "print(\"x =\", x, \"\\n\")\n",
    "print(\"softmax(x) =\", softmax(x), \"\\n\")\n",
    "print(\"sum(softmax(x))=\", np.sum(softmax(x)), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = [-4e+100, -6e+100, -8e+100] \n",
      "\n",
      "\t(denominator = 0.0 )\n",
      "softmax(x) = [ nan  nan  nan] \n",
      "\n",
      "\t(denominator = 0.0 )\n",
      "sum(softmax(x))= nan \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thebigapple/anaconda3/envs/env/lib/python3.5/site-packages/ipykernel/__main__.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# underflow example: denominator will become 0, so result is undefined\n",
    "x = [-4e100, -6e100, -8e100]\n",
    "print(\"x =\", x, \"\\n\")\n",
    "print(\"softmax(x) =\", softmax(x), \"\\n\")\n",
    "print(\"sum(softmax(x))=\", np.sum(softmax(x)), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = [4e+100, 6e+100, 8e+100] \n",
      "\n",
      "\t(denominator = inf )\n",
      "softmax(x) = [ nan  nan  nan] \n",
      "\n",
      "\t(denominator = inf )\n",
      "sum(softmax(x))= nan \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thebigapple/anaconda3/envs/env/lib/python3.5/site-packages/ipykernel/__main__.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/thebigapple/anaconda3/envs/env/lib/python3.5/site-packages/ipykernel/__main__.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  app.launch_new_instance()\n",
      "/Users/thebigapple/anaconda3/envs/env/lib/python3.5/site-packages/ipykernel/__main__.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# overflow example: denominator will become inf, so result is undefined\n",
    "x = [4e100, 6e100, 8e100]\n",
    "print(\"x =\", x, \"\\n\")\n",
    "print(\"softmax(x) =\", softmax(x), \"\\n\")\n",
    "print(\"sum(softmax(x))=\", np.sum(softmax(x)), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**improved softmax**\n",
    "\n",
    "$$\\text{softmax}(\\boldsymbol{z})_{i},\\quad \\boldsymbol{z} = \\boldsymbol{x} - \\text{max}_{i}x_{i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def improved_softmax(x):\n",
    "    print(\"\\t(max =\", np.max(x), \")\")\n",
    "    z = x - np.max(x)\n",
    "    print(\"\\t(z =\", z, \")\")\n",
    "    print(\"\\t(denominator =\", np.sum(np.exp(z)), \")\")\n",
    "    return np.exp(z)/np.sum(np.exp(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = [4.0, 6.0, 8.0] \n",
      "\n",
      "\t(max = 8.0 )\n",
      "\t(z = [-4. -2.  0.] )\n",
      "\t(denominator = 1.15365092213 )\n",
      "improved_softmax(x) = [ 0.01587624  0.11731043  0.86681333] \n",
      "\n",
      "\t(max = 8.0 )\n",
      "\t(z = [-4. -2.  0.] )\n",
      "\t(denominator = 1.15365092213 )\n",
      "sum(improved_softmax(x))= 1.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# non-problematic example\n",
    "x = [4.0, 6.0, 8.0]\n",
    "print(\"x =\", x, \"\\n\")\n",
    "print(\"improved_softmax(x) =\", improved_softmax(x), \"\\n\")\n",
    "print(\"sum(improved_softmax(x))=\", np.sum(improved_softmax(x)), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = [-4e+100, -6e+100, -8e+100] \n",
      "\n",
      "\t(max = -4e+100 )\n",
      "\t(z = [  0.00000000e+000  -2.00000000e+100  -4.00000000e+100] )\n",
      "\t(denominator = 1.0 )\n",
      "improved_softmax(x) = [ 1.  0.  0.] \n",
      "\n",
      "\t(max = -4e+100 )\n",
      "\t(z = [  0.00000000e+000  -2.00000000e+100  -4.00000000e+100] )\n",
      "\t(denominator = 1.0 )\n",
      "sum(improved_softmax(x))= 1.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# underflow example: denominator will become 0, so result is undefined\n",
    "x = [-4e100, -6e100, -8e100]\n",
    "print(\"x =\", x, \"\\n\")\n",
    "print(\"improved_softmax(x) =\", improved_softmax(x), \"\\n\")\n",
    "print(\"sum(improved_softmax(x))=\", np.sum(improved_softmax(x)), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = [4e+100, 6e+100, 8e+100] \n",
      "\n",
      "\t(max = 8e+100 )\n",
      "\t(z = [ -4.00000000e+100  -2.00000000e+100   0.00000000e+000] )\n",
      "\t(denominator = 1.0 )\n",
      "improved_softmax(x) = [ 0.  0.  1.] \n",
      "\n",
      "\t(max = 8e+100 )\n",
      "\t(z = [ -4.00000000e+100  -2.00000000e+100   0.00000000e+000] )\n",
      "\t(denominator = 1.0 )\n",
      "sum(improved_softmax(x))= 1.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# overflow example: denominator will become inf, so result is undefined\n",
    "x = [4e100, 6e100, 8e100]\n",
    "print(\"x =\", x, \"\\n\")\n",
    "print(\"improved_softmax(x) =\", improved_softmax(x), \"\\n\")\n",
    "print(\"sum(improved_softmax(x))=\", np.sum(improved_softmax(x)), \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:env]",
   "language": "python",
   "name": "conda-env-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
